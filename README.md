# ğŸ¥ TÃ¼rkÃ§e SaÄŸlÄ±k SorunlarÄ± iÃ§in Hibrit SÄ±nÄ±flandÄ±rma ve LLM TabanlÄ± Ãœretimsel Asistan (Sina)

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.38+-red.svg)](https://streamlit.io)
[![Ollama](https://img.shields.io/badge/Ollama-LLM-green.svg)](https://ollama.com)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace-yellow.svg)](https://huggingface.co/SemihBekdas)

Bu repo, TÃ¼rkÃ§e saÄŸlÄ±k alanÄ±ndaki hastaâ€“doktor etkileÅŸimlerini desteklemek iÃ§in geliÅŸtirilen iki bileÅŸenli bir NLP sistemi iÃ§erir:
1. **BranÅŸ YÃ¶nlendirme:** Hasta sorusundan uygun doktor uzmanlÄ±k alanÄ±nÄ± tahmin eden 16 sÄ±nÄ±flÄ± metin sÄ±nÄ±flandÄ±rma
2. **Ãœretimsel Asistan:** GÃ¼venli sÄ±nÄ±rlar iÃ§inde bilgilendirici yanÄ±t Ã¼reten LLM tabanlÄ± sohbet modÃ¼lÃ¼

> âš ï¸ **Yasal UyarÄ±:** Bu asistan yalnÄ±zca bilgilendirme amaÃ§lÄ±dÄ±r. Kesin tanÄ± koymaz, teÅŸhis yapmaz ve ilaÃ§/doz Ã¶neremez. TÄ±bbi ÅŸikayetleriniz iÃ§in mutlaka bir saÄŸlÄ±k kuruluÅŸuna baÅŸvurun.

---

## ğŸ“Œ Ã–zet ve KatkÄ±lar

- TÃ¼rkÃ§e saÄŸlÄ±k sorularÄ±ndan **branÅŸ yÃ¶nlendirme** (16 sÄ±nÄ±f) ve **bilgilendirici yanÄ±t Ã¼retimi** birlikte ele alÄ±ndÄ±.
- Klasik ML (TF-IDF + Logistic Regression / Linear SVM) ve transformer modelleri (BERTurk, XLM-R) aynÄ± deneysel kurgu altÄ±nda karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±.
- LLM tarafÄ±nda Llama 3.1â€“8B-Instruct, **Unsloth + LoRA (r=16) + 4-bit nicemleme** ile TÃ¼rkÃ§e tÄ±bbi diyalog verisine uyarlandÄ±.
- Veri hazÄ±rlamada **PII/promo temizliÄŸi**, **gÃ¼rÃ¼ltÃ¼ azaltma**, **sÄ±nÄ±f filtreleme ve dengeleme** uygulandÄ±.

---

## ğŸ–¥ï¸ Uygulama ArayÃ¼zÃ¼ (Streamlit)

Uygulama 3 sÃ¼tunlu bir arayÃ¼z sunar:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Klasik ML     â”‚      LLM Sohbet         â”‚   Transformer   â”‚
â”‚                 â”‚                         â”‚                 â”‚
â”‚  LogReg: %64    â”‚  ğŸ‘¤ KullanÄ±cÄ± mesajÄ±    â”‚  BERTurk: %69   â”‚
â”‚  SVM: %65       â”‚  ğŸ¤– Sina cevabÄ±         â”‚  XLM-R: %64     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- Sol: TF-IDF + Logistic Regression / Linear SVM tahminleri (etiket + olasÄ±lÄ±k)
- Orta: LLM sohbet alanÄ± (Ollama Ã¼zerinden Sina modeli)
- SaÄŸ: BERTurk ve XLM-R tahminleri (etiket + olasÄ±lÄ±k)

---

## âœ… Deneysel SonuÃ§lar (Test)

| Model | Veri | Accuracy | Macro F1 |
|------|------|---------:|---------:|
| TF-IDF + Logistic Regression | 48.816 dengeli Ã¶rnek | 0.6418 | 0.6424 |
| TF-IDF + Linear SVM | 48.816 dengeli Ã¶rnek | 0.6467 | 0.6481 |
| BERTurk (dbmdz/bert-base-turkish-cased) | 48.816 dengeli Ã¶rnek | **0.6705** | **0.6882** |
| XLM-RoBERTa (xlm-roberta-base) | 48.816 dengeli Ã¶rnek | 0.6289 | 0.6434 |

LLM fine-tuning aÅŸamasÄ±nda doÄŸrulama kaybÄ± **2.27 â†’ 2.12** seviyesine dÃ¼ÅŸmÃ¼ÅŸtÃ¼r (1 epoch SFT).

---

## ğŸ“Š Veri Setleri ve HazÄ±rlama

| GÃ¶rev | Veri Seti | Ham Boyut | Ã‡alÄ±ÅŸmada KullanÄ±lan |
|------|-----------|-----------|----------------------|
| BranÅŸ sÄ±nÄ±flandÄ±rma | [alibayram/doktorsitesi](https://huggingface.co/datasets/alibayram/doktorsitesi) | 150.105 train / 37.527 test | 16 sÄ±nÄ±f, 48.816 dengeli Ã¶rnek (41.493 train / 7.323 val) + 17.888 test |
| LLM fine-tuning | [kayrab/patient-doctor-qa-tr-167732](https://huggingface.co/datasets/kayrab/patient-doctor-qa-tr-167732) | 503.196 train / 60.000 test | 20 sÄ±nÄ±f, 60.000 dengeli Ã¶rnek (54.000 train / 6.000 val) |

Lisans/eriÅŸim notu: `alibayram/doktorsitesi` veri seti HF Ã¼zerinde â€œgatedâ€ ve CC BY-NC 4.0 lisanslÄ±dÄ±r; `kayrab/patient-doctor-qa-tr-167732` veri seti MIT lisanslÄ±dÄ±r.

**Ortak temizlik adÄ±mlarÄ±:**
- PII temizliÄŸi (URL, eâ€‘posta, telefon vb.)
- TanÄ±tÄ±m/iletiÅŸim satÄ±rlarÄ±nÄ±n silinmesi (randevu, tel, whatsapp, klinik vb.)
- Unicode ve boÅŸluk normalizasyonu
- Yinelenen kayÄ±tlarÄ±n kaldÄ±rÄ±lmasÄ±

**LLM iÃ§in ek filtreler:**
- Ä°laÃ§/doz istekleri ve riskli kalÄ±plarÄ±n elenmesi
- Ã‡ok kÄ±sa/Ã§ok uzun Ã¶rneklerin filtrelenmesi

---

## ğŸ§ª YÃ¶ntemler

### 1) Klasik ML (TF-IDF + LogReg / Linear SVM)
- TÃ¼rkÃ§e lowercasing, sayÄ±sal normalizasyon, karakter temizliÄŸi
- Stop-word Ã§Ä±karÄ±mÄ± + TurkishStemmer ile kÃ¶k bulma
- TF-IDF vektÃ¶rleÅŸtirme: `ngram_range=(1,2)`, `max_features=20000`
- C âˆˆ {0.1, 0.5, 1.0, 3.0, 10.0} aralÄ±ÄŸÄ±nda doÄŸrulama Macro F1â€™e gÃ¶re seÃ§im

### 2) Transformer (BERTurk / XLM-R)
- Minimal temizlik + model tokenizerâ€™Ä±
- Fine-tuning: 3 epoch, lr=2e-5, batch=16, max_len=128
- Streamlit inference sÄ±rasÄ±nda tokenizer `max_length=256` ile kÄ±saltma yapar

### 3) LLM (Llama 3.1â€“8B + Unsloth + LoRA)
- Temel model: `Meta-Llama-3.1-8B-Instruct`
- 4-bit nicemleme + LoRA (r=16)
- SFT: 1 epoch, efektif batch â‰ˆ 64, `adamw_8bit`, cosine LR
- Chat ÅŸablonu: **system / user / assistant** formatÄ±
- KayÄ±p sadece assistant yanÄ±tÄ± Ã¼zerinde hesaplanÄ±r (train_on_responses_only)

---

## ğŸ“ Proje YapÄ±sÄ±

```
â”œâ”€â”€ streamlit_app.py              # Ana Streamlit uygulamasÄ±
â”œâ”€â”€ Modelfile                     # Ollama model konfigÃ¼rasyonu
â”œâ”€â”€ requirements.txt              # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ saved_models/                 # Klasik ML + Transformer aÄŸÄ±rlÄ±klarÄ±
â”‚   â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ berturk-doctorsitesi-best/
â”‚   â””â”€â”€ xlmr-doctorsitesi-best/
â”œâ”€â”€ outputs/                      # EÄŸitim grafikleri ve confusion matrix gÃ¶rselleri
â”œâ”€â”€ NlpPipeline.ipynb             # ML + Transformer eÄŸitim pipeline
â”œâ”€â”€ Llama3_1_(8B).ipynb           # LLM fine-tuning (LoRA)
â”œâ”€â”€ Rapor.pdf                     # DetaylÄ± proje raporu
â””â”€â”€ sunum/                        # Sunum dosyalarÄ±
```

> Not: Uygulama `saved_models/` klasÃ¶rÃ¼ndeki aÄŸÄ±rlÄ±klarÄ± bekler. Bu klasÃ¶rler yoksa aynÄ± isimlerle yerleÅŸtirmeniz gerekir.

---

## ğŸ§© Modelleri EÄŸitme (NlpPipeline.ipynb)

Bu repodaki **klasik ML ve transformer modellerini** yeniden Ã¼retmek iÃ§in `NlpPipeline.ipynb` Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r. Notebook, veri temizleme, dengeleme, eÄŸitim ve deÄŸerlendirme adÄ±mlarÄ±nÄ± uÃ§tan uca iÃ§erir ve Ã§Ä±ktÄ±larÄ± `saved_models/` altÄ±na kaydeder.

Ã–zet akÄ±ÅŸ:
1. `NlpPipeline.ipynb` iÃ§indeki veri hazÄ±rlama hÃ¼crelerini Ã§alÄ±ÅŸtÄ±r.
2. TF-IDF + Logistic Regression / Linear SVM eÄŸitimini tamamla.
3. BERTurk ve XLM-R fine-tuning adÄ±mlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±r.
4. Ãœretilen klasÃ¶rler `saved_models/ml/`, `saved_models/berturk-doctorsitesi-best/`, `saved_models/xlmr-doctorsitesi-best/` altÄ±nda oluÅŸur.

> UyarÄ±: Notebook eÄŸitimi GPU gerektirebilir. Transformer ve LLM eÄŸitimleri iÃ§in Colab/A100 gibi ortamlar Ã¶nerilir.

---

## ğŸš€ Kurulum

### Gereksinimler
- Python 3.10+
- [Ollama](https://ollama.com/download) (Mac/Linux/Windows)
- 8GB+ RAM (LLM iÃ§in daha yÃ¼ksek bellek Ã¶nerilir)

### 1) Repo'yu Klonla

```bash
git clone https://github.com/semihbekdas/yapay-zeka-saglik-asistani-sina.git
cd yapay-zeka-saglik-asistani-sina
```

### 2) Sanal Ortam ve BaÄŸÄ±mlÄ±lÄ±klar

```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# veya
venv\Scripts\activate     # Windows

pip install -r requirements.txt
```

### 3) Ollama Modeli Kur

```bash
ollama serve
ollama create sina -f Modelfile
ollama run sina
```

---

## â–¶ï¸ Ã‡alÄ±ÅŸtÄ±rma

**Terminal 1:** Ollama sunucusu
```bash
ollama serve
```

**Terminal 2:** Streamlit uygulamasÄ±
```bash
source venv/bin/activate
streamlit run streamlit_app.py
```

TarayÄ±cÄ±da `http://localhost:8501` adresine git.

---

## âš™ï¸ KonfigÃ¼rasyon

Streamlit uygulamasÄ± aÅŸaÄŸÄ±daki ortam deÄŸiÅŸkenlerini okur:

```bash
export OLLAMA_MODEL=sina
export OLLAMA_BASE_URL=http://localhost:11434
```

`Modelfile` iÃ§eriÄŸi Ollama tarafÄ±ndaki model davranÄ±ÅŸÄ±nÄ± belirler.

---

## ğŸ› ï¸ Sorun Giderme

| Sorun | Ã‡Ã¶zÃ¼m |
|-------|-------|
| `ollama: command not found` | [Ollama'yÄ± indir](https://ollama.com) |
| `Connection refused` | `ollama serve` Ã§alÄ±ÅŸtÄ±r |
| `Model not found` | `ollama create sina -f Modelfile` Ã§alÄ±ÅŸtÄ±r |
| `Out of memory` | Daha yÃ¼ksek RAM/GPU kullan veya `num_ctx` deÄŸerini dÃ¼ÅŸÃ¼r |
| `NLTK data missing` | `python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab'); nltk.download('stopwords')"` |

---

## ğŸ” SÄ±nÄ±rlÄ±lÄ±klar ve Gelecek Ã‡alÄ±ÅŸmalar

- Etiketler arasÄ±nda doÄŸal Ã¶rtÃ¼ÅŸmeler (Ã¶zellikle alt branÅŸlar) nedeniyle karÄ±ÅŸmalar oluÅŸur.
- Veri gÃ¼rÃ¼ltÃ¼sÃ¼, yazÄ±m hatalarÄ± ve kÄ±sa/eksik sorular performansÄ± sÄ±nÄ±rlar.
- LLM Ã§Ä±ktÄ±larÄ±nÄ±n gÃ¼venliÄŸi iÃ§in nitel deÄŸerlendirme ve uzman geri bildirimi gÃ¼Ã§lendirilmelidir.
- Daha kapsamlÄ± hiperparametre aramasÄ± ve hiyerarÅŸik branÅŸ etiketleme performansÄ± artÄ±rabilir.

---

## ğŸ“š Kaynaklar

- [LLM Model (Hugging Face)](https://huggingface.co/SemihBekdas/Llama3.1-8B-TR-PatientQA-LoRA-v1)
- [SÄ±nÄ±flandÄ±rma Verisi](https://huggingface.co/datasets/alibayram/doktorsitesi)
- [LLM EÄŸitim Verisi](https://huggingface.co/datasets/kayrab/patient-doctor-qa-tr-167732)
- [BERTurk](https://huggingface.co/dbmdz/bert-base-turkish-cased)
- [Llama 3.1](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)

---

## ğŸ‘¤ GeliÅŸtirici

**Semih BekdaÅŸ**

- GitHub: [@semihbekdas](https://github.com/semihbekdas)
- HuggingFace: [SemihBekdas](https://huggingface.co/SemihBekdas)
